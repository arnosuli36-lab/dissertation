import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.neural_network import MLPRegressor
from sklearn.model_selection import TimeSeriesSplit, cross_val_score
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import scipy.stats as stats
import warnings
import os
import glob
from itertools import combinations
import seaborn as sns
import time

warnings.filterwarnings('ignore')

# Enhanced Chinese font settings - completely solve garbled text issues
import matplotlib.font_manager as fm

# Enhanced font settings
matplotlib.rcParams['font.family'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans', 'Arial']
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans', 'Arial', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.dpi'] = 100
plt.rcParams['font.size'] = 11
plt.rcParams['axes.titlesize'] = 13
plt.rcParams['axes.labelsize'] = 11
plt.rcParams['xtick.labelsize'] = 10
plt.rcParams['ytick.labelsize'] = 10
plt.rcParams['legend.fontsize'] = 10

# å¼ºåˆ¶è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
try:
    # å°è¯•è®¾ç½®SimHeiå­—ä½“
    font_path = fm.findfont(fm.FontProperties(family='SimHei'))
    if 'SimHei' not in font_path:
        # å¦‚æœSimHeiä¸å¯ç”¨ï¼Œå°è¯•å…¶ä»–ä¸­æ–‡å­—ä½“
        for font_name in ['Microsoft YaHei', 'STHeiti', 'STSong', 'FangSong']:
            try:
                fm.FontProperties(family=font_name)
                plt.rcParams['font.sans-serif'] = [font_name] + plt.rcParams['font.sans-serif']
                break
            except:
                continue
except:
    # å¦‚æœéƒ½ä¸è¡Œï¼Œä½¿ç”¨ç³»ç»Ÿé»˜è®¤ä½†è®¾ç½®è´Ÿå·æ­£å¸¸æ˜¾ç¤º
    plt.rcParams['axes.unicode_minus'] = False

# è®¾ç½®éšæœºç§å­
np.random.seed(42)

# æ•°æ®è·¯å¾„
desktop_path = r"C:\Users\13616\Desktop"
data_folder = r"C:\Users\13616\Desktop\åŸå§‹æ•°æ®"


def find_stock_price_file(folder_path):
    """æ™ºèƒ½é€‰æ‹©è‚¡ç¥¨ä»·æ ¼æ•°æ®æ–‡ä»¶"""
    if not os.path.exists(folder_path):
        print(f"æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}")
        return None, []

    csv_files = glob.glob(os.path.join(folder_path, "*.csv"))

    if not csv_files:
        print(f"åœ¨æ–‡ä»¶å¤¹ {folder_path} ä¸­æœªæ‰¾åˆ°CSVæ–‡ä»¶")
        return None, []

    print(f"\nğŸ“ å‘ç°çš„CSVæ–‡ä»¶:")
    for i, file in enumerate(csv_files):
        file_name = os.path.basename(file)
        file_size = os.path.getsize(file) / 1024 / 1024  # MB
        print(f"â”œâ”€ {i + 1}. {file_name} ({file_size:.2f} MB)")

    # ä¼˜å…ˆé€‰æ‹©æ”¶ç›˜ä»·æ–‡ä»¶
    priority_files = []
    for file in csv_files:
        filename = os.path.basename(file).lower()
        if 'close' in filename and 'ftse' in filename:
            priority_files.append(file)

    if not priority_files:
        for file in csv_files:
            filename = os.path.basename(file).lower()
            if any(keyword in filename for keyword in ['price', 'open', 'high', 'low']) and 'ftse' in filename:
                priority_files.append(file)

    selected = priority_files[0] if priority_files else csv_files[0]
    print(f"â””â”€ é€‰ä¸­æ–‡ä»¶: {os.path.basename(selected)} (æœ€é€‚åˆè‚¡ç¥¨åˆ†æ)")

    return selected, csv_files


# å¯»æ‰¾æ•°æ®æ–‡ä»¶
selected_file, all_csv_files = find_stock_price_file(data_folder)
data_path = selected_file


class EnhancedH1H4ResearchSystem:
    def __init__(self):
        self.data = None
        self.original_data = None
        self.all_stocks = []
        self.h1_results = []
        self.h2_results = []
        self.h3_results = []
        self.h4_results = []
        self.vftse_data = None
        self.figures_saved = []
        self.error_log = []
        self.feature_importance_data = {}  # æ–°å¢ï¼šç‰¹å¾é‡è¦æ€§æ•°æ®
        self.prediction_examples = {}  # æ–°å¢ï¼šPredictionç¤ºä¾‹æ•°æ®

    def safe_chinese_title(self, title):
        """å®‰å…¨çš„ä¸­æ–‡æ ‡é¢˜è®¾ç½®"""
        try:
            return title
        except:
            return title.encode('utf-8', errors='ignore').decode('utf-8', errors='ignore')

    def load_stock_data(self, file_path):
        """åŠ è½½è‚¡ç¥¨æ•°æ®"""
        print(f"æ­£åœ¨è¯»å–è‚¡ç¥¨æ•°æ®æ–‡ä»¶: {os.path.basename(file_path)}")
        print("=" * 80)

        try:
            self.data = pd.read_csv(file_path, encoding='utf-8')
            self.original_data = self.data.copy()

            print(f"âœ… æˆåŠŸè¯»å–æ•°æ®")
            print(f"â”œâ”€ åŸå§‹æ•°æ®è§„æ¨¡: {self.data.shape}")

            # å¤„ç†æ—¥æœŸåˆ—
            if 'Date' in self.data.columns or 'date' in self.data.columns:
                date_col = 'Date' if 'Date' in self.data.columns else 'date'
                self.data[date_col] = pd.to_datetime(self.data[date_col])
                self.data = self.data.sort_values(date_col).reset_index(drop=True)
                print(f"â”œâ”€ æ—¥æœŸåˆ—å¤„ç†æˆåŠŸ: {date_col}")

            # è·å–æ‰€æœ‰è‚¡ç¥¨åˆ—
            numeric_cols = []
            for col in self.data.columns:
                if col.lower() not in ['date', 'unnamed: 0', 'index']:
                    try:
                        temp_series = pd.to_numeric(self.data[col], errors='coerce')
                        if temp_series.notna().sum() > 100:
                            numeric_cols.append(col)
                    except:
                        continue

            self.all_stocks = numeric_cols

            print(f"â”œâ”€ å‘ç°è‚¡ç¥¨æ•°: {len(self.all_stocks)} åª")
            print(f"â”œâ”€ æ•°æ®æ—¶é—´è·¨åº¦: {len(self.data)} ä¸ªæ—¶é—´ç‚¹")

            if len(self.all_stocks) == 0:
                raise Exception("æ²¡æœ‰å‘ç°æœ‰æ•ˆçš„è‚¡ç¥¨æ•°æ®")

            # æ¸…ç†æ•°æ®
            for col in self.all_stocks:
                self.data[col] = pd.to_numeric(self.data[col], errors='coerce')

            self.data = self.data.dropna(how='all', subset=self.all_stocks)

            print(f"â”œâ”€ æ¸…ç†åæ•°æ®: {len(self.data)} è¡Œ")
            print(f"â””â”€ æœ€ç»ˆè‚¡ç¥¨æ•°: {len(self.all_stocks)} åª")

            self.load_vftse_data()

            return True

        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            self.error_log.append(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False

    def load_vftse_data(self):
        """åŠ è½½VFTSEæƒ…ç»ªæŒ‡æ ‡æ•°æ®"""
        try:
            vftse_file = os.path.join(data_folder, "FTSE100_Volatility_2014_2024.csv")
            if os.path.exists(vftse_file):
                vftse_df = pd.read_csv(vftse_file)
                if len(vftse_df.columns) >= 2:
                    self.vftse_data = vftse_df.iloc[:, 1].values
                    print(f"âœ… VFTSEæƒ…ç»ªæŒ‡æ ‡åŠ è½½æˆåŠŸ: {len(self.vftse_data)} ä¸ªæ•°æ®ç‚¹")
                else:
                    self.vftse_data = None
            else:
                self.vftse_data = None
                print("âš ï¸ æœªæ‰¾åˆ°VFTSEæ–‡ä»¶ï¼Œå°†æ¨¡æ‹Ÿæƒ…ç»ªæŒ‡æ ‡")
        except Exception as e:
            self.vftse_data = None
            print(f"âš ï¸ VFTSEåŠ è½½å¤±è´¥: {e}")

    def create_vftse_sentiment(self, stock_prices):
        """åˆ›å»ºVFTSEæƒ…ç»ªæŒ‡æ ‡"""
        if self.vftse_data is not None and len(self.vftse_data) >= len(stock_prices):
            return self.vftse_data[:len(stock_prices)]
        else:
            returns = pd.Series(stock_prices).pct_change().fillna(0)
            rolling_vol = returns.rolling(window=20, min_periods=1).std() * np.sqrt(252)
            vftse_raw = rolling_vol * 100
            return vftse_raw.values

    def create_market_regime(self, vftse_values):
        """åˆ›å»ºå¸‚åœºçŠ¶æ€åˆ†å±‚"""
        try:
            q75 = np.quantile(vftse_values, 0.75)
            q25 = np.quantile(vftse_values, 0.25)

            regime = []
            for s_t in vftse_values:
                if s_t >= q75:
                    regime.append('HighVol')
                elif s_t <= q25:
                    regime.append('LowVol')
                else:
                    regime.append('Mid')

            return np.array(regime), {'q75': q75, 'q25': q25}

        except Exception as e:
            print(f"âš ï¸ å¸‚åœºçŠ¶æ€åˆ†å±‚å¤±è´¥: {e}")
            return np.array(['Mid'] * len(vftse_values)), {'q75': 0, 'q25': 0}

    def create_target_variable(self, prices, H=5):
        """åˆ›å»ºç›®æ ‡å˜é‡: y_t(H) = ln P_{t+H} - ln P_t"""
        try:
            log_prices = np.log(prices + 1e-8)
            target = []

            for i in range(len(log_prices) - H):
                y_h = log_prices[i + H] - log_prices[i]
                target.append(y_h)

            return np.array(target)
        except Exception as e:
            print(f"âš ï¸ ç›®æ ‡å˜é‡åˆ›å»ºå¤±è´¥: {e}")
            return np.array([])

    def create_feature_set(self, stock_prices, feature_type="full", include_obv=True, include_vftse=True):
        """åˆ›å»ºç‰¹å¾é›†"""
        try:
            prices = pd.Series(stock_prices)
            features = pd.DataFrame()

            # åŸºç¡€ä»·æ ¼ç‰¹å¾
            if feature_type in ["price_only", "price_tech", "full"]:
                features['Price'] = prices
                features['Log_Price'] = np.log(prices + 1e-8)
                returns = prices.pct_change().fillna(0)
                features['Return'] = returns
                features['Return_Lag1'] = returns.shift(1).fillna(0)
                features['Return_Lag2'] = returns.shift(2).fillna(0)

            # æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾
            if feature_type in ["price_tech", "full"]:
                # SMAæŒ‡æ ‡
                features['SMA_15'] = prices.rolling(window=15, min_periods=1).mean()
                features['SMA_45'] = prices.rolling(window=45, min_periods=1).mean()

                # RSIæŒ‡æ ‡
                delta = prices.diff()
                gain = delta.where(delta > 0, 0).rolling(window=14, min_periods=1).mean()
                loss = (-delta.where(delta < 0, 0)).rolling(window=14, min_periods=1).mean()
                rs = gain / (loss + 1e-8)
                features['RSI'] = 100 - (100 / (1 + rs))

                # MACDæŒ‡æ ‡
                ema_12 = prices.ewm(span=12, min_periods=1).mean()
                ema_26 = prices.ewm(span=26, min_periods=1).mean()
                features['MACD'] = ema_12 - ema_26
                features['MACD_Signal'] = features['MACD'].ewm(span=9, min_periods=1).mean()

                # Bollinger Bands
                bb_middle = prices.rolling(window=20, min_periods=1).mean()
                bb_std = prices.rolling(window=20, min_periods=1).std()
                features['BB_Upper'] = bb_middle + (bb_std * 2)
                features['BB_Lower'] = bb_middle - (bb_std * 2)
                features['BB_Position'] = (prices - features['BB_Lower']) / (
                            features['BB_Upper'] - features['BB_Lower'] + 1e-8)

            # OBVæŒ‡æ ‡
            if feature_type == "full" and include_obv:
                price_change = prices.diff()
                obv = np.zeros(len(prices))
                for i in range(1, len(prices)):
                    if price_change.iloc[i] > 0:
                        obv[i] = obv[i - 1] + 1
                    elif price_change.iloc[i] < 0:
                        obv[i] = obv[i - 1] - 1
                    else:
                        obv[i] = obv[i - 1]
                features['OBV'] = obv
                features['OBV_MA'] = pd.Series(obv).rolling(window=10, min_periods=1).mean()

            # VFTSEæƒ…ç»ªæŒ‡æ ‡
            if feature_type == "full" and include_vftse:
                vftse = self.create_vftse_sentiment(stock_prices)
                if len(vftse) == len(features):
                    features['VFTSE'] = vftse
                    vftse_mean = np.mean(vftse)
                    vftse_std = np.std(vftse)
                    features['VFTSE_zscore'] = (vftse - vftse_mean) / (vftse_std + 1e-8)

            # æ¸…ç†æ•°æ®
            features = features.replace([np.inf, -np.inf], np.nan)
            features = features.fillna(method='ffill').fillna(0)

            return features

        except Exception as e:
            print(f"âš ï¸ ç‰¹å¾åˆ›å»ºå¤±è´¥: {e}")
            return pd.DataFrame()

    def train_models_with_importance(self, X_train, y_train, X_test, model_types=None):
        """è®­ç»ƒæ¨¡å‹å¹¶è®°å½•ç‰¹å¾é‡è¦æ€§"""
        if model_types is None:
            model_types = ['SVR', 'RF', 'LSTM_MLP']

        models = {}
        predictions = {}

        try:
            if 'SVR' in model_types:
                models['SVR'] = SVR(C=10, epsilon=0.1, kernel='rbf')
            if 'RF' in model_types:
                models['RF'] = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)
            if 'LSTM_MLP' in model_types:
                models['LSTM_MLP'] = MLPRegressor(hidden_layer_sizes=(50, 25), max_iter=500, random_state=42)

            for name, model in models.items():
                try:
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                    predictions[name] = y_pred

                    # è®°å½•ç‰¹å¾é‡è¦æ€§ï¼ˆéšæœºæ£®æ—ï¼‰
                    if name == 'RF' and hasattr(model, 'feature_importances_'):
                        self.feature_importance_data[name] = model.feature_importances_

                except Exception as e:
                    print(f"âš ï¸ æ¨¡å‹ {name} è®­ç»ƒå¤±è´¥: {e}")
                    self.error_log.append(f"æ¨¡å‹ {name} è®­ç»ƒå¤±è´¥: {e}")
                    continue

        except Exception as e:
            print(f"âš ï¸ Model trainingæ‰¹æ¬¡å¤±è´¥: {e}")

        return predictions

    def calculate_metrics(self, y_true, y_pred):
        """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
        try:
            mae = mean_absolute_error(y_true, y_pred)
            rmse = np.sqrt(mean_squared_error(y_true, y_pred))
            r2 = r2_score(y_true, y_pred)
            direction_accuracy = np.mean(np.sign(y_true) == np.sign(y_pred))

            return {'MAE': mae, 'RMSE': rmse, 'R2': r2, 'Direction_Accuracy': direction_accuracy}
        except Exception as e:
            print(f"âš ï¸ æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
            return {'MAE': np.nan, 'RMSE': np.nan, 'R2': np.nan, 'Direction_Accuracy': np.nan}

    def conduct_h1_hypothesis(self, sample_stocks=50):
        """H1å‡è®¾: æ¨¡å‹å¯¹æ¯” + å¸‚åœºçŠ¶æ€åˆ†å±‚"""
        print(f"\nğŸ¯ H1å‡è®¾ï¼šæ¨¡å‹å¯¹æ¯”ç ”ç©¶ (SVR vs RF vs LSTM) + å¸‚åœºçŠ¶æ€åˆ†å±‚")
        print("=" * 60)

        sample_stocks_list = self.all_stocks[:sample_stocks] if len(
            self.all_stocks) > sample_stocks else self.all_stocks
        h1_results = []

        for i, stock in enumerate(sample_stocks_list):
            if i % 10 == 0:
                print(f"è¿›åº¦: {i + 1}/{len(sample_stocks_list)} åªè‚¡ç¥¨")

            try:
                prices = self.data[stock].dropna().values
                if len(prices) < 200:
                    continue

                features = self.create_feature_set(prices, feature_type="full")
                target = self.create_target_variable(prices, H=5)

                if features.empty or len(target) == 0:
                    continue

                min_len = min(len(features), len(target))
                features = features.iloc[:min_len]
                target = target[:min_len]

                if len(features) < 100:
                    continue

                # åˆ›å»ºå¸‚åœºçŠ¶æ€åˆ†å±‚
                if 'VFTSE_zscore' in features.columns:
                    market_regime, regime_stats = self.create_market_regime(features['VFTSE_zscore'].values)
                else:
                    market_regime = np.array(['Mid'] * len(features))
                    regime_stats = {'q75': 0, 'q25': 0}

                # æ—¶é—´åºåˆ—åˆ†å‰²
                split_point = int(len(features) * 0.8)
                X_train = features.iloc[:split_point]
                X_test = features.iloc[split_point:]
                y_train = target[:split_point]
                y_test = target[split_point:]
                regime_test = market_regime[split_point:]

                # æ ‡å‡†åŒ–
                scaler = StandardScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_test_scaled = scaler.transform(X_test)

                # è®­ç»ƒæ¨¡å‹
                predictions = self.train_models_with_importance(X_train_scaled, y_train, X_test_scaled)

                # ä¿å­˜Predictionç¤ºä¾‹ï¼ˆç¬¬ä¸€åªè‚¡ç¥¨ï¼‰
                if i == 0 and len(predictions) > 0:
                    best_model = max(predictions.keys(),
                                     key=lambda x: self.calculate_metrics(y_test, predictions[x])['R2'])
                    self.prediction_examples['y_true'] = y_test[:50]  # å‰50ä¸ªPredictionç‚¹
                    self.prediction_examples['y_pred'] = predictions[best_model][:50]
                    self.prediction_examples['model_name'] = best_model
                    self.prediction_examples['stock_name'] = stock

                # è¯„ä¼°ç»“æœ
                for model_name, y_pred in predictions.items():
                    # æ€»ä½“è¯„ä¼°
                    metrics = self.calculate_metrics(y_test, y_pred)
                    h1_results.append({
                        'Stock': stock,
                        'Model': model_name,
                        'Hypothesis': 'H1',
                        'Regime': 'Overall',
                        **metrics
                    })

                    # åˆ†å±‚è¯„ä¼°
                    for regime_type in ['HighVol', 'LowVol', 'Mid']:
                        regime_mask = regime_test == regime_type
                        if np.sum(regime_mask) > 5:
                            try:
                                y_test_regime = y_test[regime_mask]
                                y_pred_regime = y_pred[regime_mask]
                                metrics_regime = self.calculate_metrics(y_test_regime, y_pred_regime)
                                h1_results.append({
                                    'Stock': stock,
                                    'Model': model_name,
                                    'Hypothesis': 'H1',
                                    'Regime': regime_type,
                                    **metrics_regime
                                })
                            except Exception as e:
                                continue

            except Exception as e:
                self.error_log.append(f"H1-{stock}: {e}")
                continue

        self.h1_results = h1_results
        print(f"âœ… H1å‡è®¾å®Œæˆ: {len(h1_results)} ä¸ªå®éªŒ (å«åˆ†å±‚)")
        return len(h1_results) > 0

    def conduct_h2_hypothesis(self, sample_stocks=30):
        """H2å‡è®¾: Feature engineering"""
        print(f"\nğŸ”§ H2å‡è®¾ï¼šFeature engineeringç ”ç©¶ (ä»·æ ¼ vs ä»·æ ¼+æŠ€æœ¯æŒ‡æ ‡)")
        print("=" * 60)

        sample_stocks_list = self.all_stocks[:sample_stocks] if len(
            self.all_stocks) > sample_stocks else self.all_stocks
        h2_results = []
        feature_sets = [
            ("Price_Only", "price_only"),
            ("Price_Tech", "price_tech"),
            ("Full_Features", "full")
        ]

        for i, stock in enumerate(sample_stocks_list):
            if i % 10 == 0:
                print(f"è¿›åº¦: {i + 1}/{len(sample_stocks_list)} åªè‚¡ç¥¨")

            try:
                prices = self.data[stock].dropna().values
                if len(prices) < 200:
                    continue

                target = self.create_target_variable(prices, H=5)
                if len(target) == 0:
                    continue

                for feature_name, feature_type in feature_sets:
                    try:
                        features = self.create_feature_set(prices, feature_type=feature_type)

                        if features.empty:
                            continue

                        min_len = min(len(features), len(target))
                        features = features.iloc[:min_len]
                        target_aligned = target[:min_len]

                        if len(features) < 100:
                            continue

                        split_point = int(len(features) * 0.8)
                        X_train = features.iloc[:split_point]
                        X_test = features.iloc[split_point:]
                        y_train = target_aligned[:split_point]
                        y_test = target_aligned[split_point:]

                        scaler = StandardScaler()
                        X_train_scaled = scaler.fit_transform(X_train)
                        X_test_scaled = scaler.transform(X_test)

                        model = RandomForestRegressor(n_estimators=100, random_state=42)
                        model.fit(X_train_scaled, y_train)
                        y_pred = model.predict(X_test_scaled)

                        metrics = self.calculate_metrics(y_test, y_pred)
                        h2_results.append({
                            'Stock': stock,
                            'FeatureSet': feature_name,
                            'FeatureCount': len(features.columns),
                            'Hypothesis': 'H2',
                            **metrics
                        })

                    except Exception as e:
                        self.error_log.append(f"H2-{stock}-{feature_name}: {e}")
                        continue

            except Exception as e:
                self.error_log.append(f"H2-{stock}: {e}")
                continue

        self.h2_results = h2_results
        print(f"âœ… H2å‡è®¾å®Œæˆ: {len(h2_results)} ä¸ªå®éªŒ")
        return len(h2_results) > 0

    def conduct_h3_hypothesis(self, sample_stocks=30):
        """H3å‡è®¾: OBVè´¡çŒ®"""
        print(f"\nâ­ H3å‡è®¾ï¼šOBVæŒ‡æ ‡è´¡çŒ®ç ”ç©¶")
        print("=" * 60)

        sample_stocks_list = self.all_stocks[:sample_stocks] if len(
            self.all_stocks) > sample_stocks else self.all_stocks
        h3_results = []

        for i, stock in enumerate(sample_stocks_list):
            if i % 10 == 0:
                print(f"è¿›åº¦: {i + 1}/{len(sample_stocks_list)} åªè‚¡ç¥¨")

            try:
                prices = self.data[stock].dropna().values
                if len(prices) < 200:
                    continue

                target = self.create_target_variable(prices, H=5)
                if len(target) == 0:
                    continue

                for include_obv in [False, True]:
                    obv_flag = "With_OBV" if include_obv else "Without_OBV"

                    try:
                        features = self.create_feature_set(prices, feature_type="full", include_obv=include_obv)

                        if features.empty:
                            continue

                        min_len = min(len(features), len(target))
                        features = features.iloc[:min_len]
                        target_aligned = target[:min_len]

                        if len(features) < 100:
                            continue

                        split_point = int(len(features) * 0.8)
                        X_train = features.iloc[:split_point]
                        X_test = features.iloc[split_point:]
                        y_train = target_aligned[:split_point]
                        y_test = target_aligned[split_point:]

                        scaler = StandardScaler()
                        X_train_scaled = scaler.fit_transform(X_train)
                        X_test_scaled = scaler.transform(X_test)

                        model = RandomForestRegressor(n_estimators=100, random_state=42)
                        model.fit(X_train_scaled, y_train)
                        y_pred = model.predict(X_test_scaled)

                        metrics = self.calculate_metrics(y_test, y_pred)
                        h3_results.append({
                            'Stock': stock,
                            'OBV_Flag': obv_flag,
                            'FeatureCount': len(features.columns),
                            'Hypothesis': 'H3',
                            **metrics
                        })

                    except Exception as e:
                        self.error_log.append(f"H3-{stock}-{obv_flag}: {e}")
                        continue

            except Exception as e:
                self.error_log.append(f"H3-{stock}: {e}")
                continue

        self.h3_results = h3_results
        print(f"âœ… H3å‡è®¾å®Œæˆ: {len(h3_results)} ä¸ªå®éªŒ")
        return len(h3_results) > 0

    def conduct_h4_hypothesis(self, sample_stocks=30):
        """H4å‡è®¾: Predictionçª—å£ + å¸‚åœºçŠ¶æ€åˆ†å±‚ + å¤šæ¨¡å‹å¯¹æ¯” (SVR, RF, LSTM)"""
        print(f"\nğŸ“… H4å‡è®¾ï¼šPredictionçª—å£ç ”ç©¶ (çŸ­ä¸­é•¿æœŸ) + å¸‚åœºçŠ¶æ€åˆ†å±‚ + å¤šæ¨¡å‹å¯¹æ¯”")
        print("=" * 60)

        sample_stocks_list = self.all_stocks[:sample_stocks] if len(
            self.all_stocks) > sample_stocks else self.all_stocks
        h4_results = []
        horizons = [5, 10, 30, 60]
        model_types = ['SVR', 'RF', 'LSTM_MLP']  # ä¸‰ç§æ¨¡å‹å¯¹æ¯”

        for i, stock in enumerate(sample_stocks_list):
            if i % 10 == 0:
                print(f"H4è¿›åº¦: {i + 1}/{len(sample_stocks_list)} åªè‚¡ç¥¨")

            try:
                prices = self.data[stock].dropna().values
                if len(prices) < 300:
                    continue

                for H in horizons:
                    horizon_type = "short" if H <= 10 else "medium" if H <= 30 else "long"

                    try:
                        features = self.create_feature_set(prices, feature_type="full")
                        target = self.create_target_variable(prices, H=H)

                        if features.empty or len(target) == 0:
                            continue

                        min_len = min(len(features), len(target))
                        features = features.iloc[:min_len]
                        target_aligned = target[:min_len]

                        if len(features) < 100:
                            continue

                        # å¸‚åœºçŠ¶æ€åˆ†å±‚
                        if 'VFTSE_zscore' in features.columns:
                            market_regime, _ = self.create_market_regime(features['VFTSE_zscore'].values)
                        else:
                            market_regime = np.array(['Mid'] * len(features))

                        split_point = int(len(features) * 0.8)
                        X_train = features.iloc[:split_point]
                        X_test = features.iloc[split_point:]
                        y_train = target_aligned[:split_point]
                        y_test = target_aligned[split_point:]
                        regime_test = market_regime[split_point:]

                        scaler = StandardScaler()
                        X_train_scaled = scaler.fit_transform(X_train)
                        X_test_scaled = scaler.transform(X_test)

                        # ğŸ”¥ æ ¸å¿ƒä¿®æ”¹: ä½¿ç”¨å¤šModel training
                        predictions = self.train_models_with_importance(X_train_scaled, y_train, X_test_scaled,
                                                                        model_types)

                        # å¯¹æ¯ä¸ªæ¨¡å‹è¿›è¡Œè¯„ä¼°
                        for model_name, y_pred in predictions.items():
                            # æ€»ä½“è¯„ä¼°
                            metrics = self.calculate_metrics(y_test, y_pred)
                            h4_results.append({
                                'Stock': stock,
                                'Model': model_name,  # æ–°å¢ï¼šæ¨¡å‹ç±»å‹
                                'Horizon_H': H,
                                'Horizon_Type': horizon_type,
                                'Hypothesis': 'H4',
                                'Regime': 'Overall',
                                **metrics
                            })

                            # åˆ†å±‚è¯„ä¼°
                            for regime_type in ['HighVol', 'LowVol', 'Mid']:
                                regime_mask = regime_test == regime_type
                                if np.sum(regime_mask) > 5:
                                    try:
                                        y_test_regime = y_test[regime_mask]
                                        y_pred_regime = y_pred[regime_mask]
                                        metrics_regime = self.calculate_metrics(y_test_regime, y_pred_regime)
                                        h4_results.append({
                                            'Stock': stock,
                                            'Model': model_name,  # æ–°å¢ï¼šæ¨¡å‹ç±»å‹
                                            'Horizon_H': H,
                                            'Horizon_Type': horizon_type,
                                            'Hypothesis': 'H4',
                                            'Regime': regime_type,
                                            **metrics_regime
                                        })
                                    except Exception as e:
                                        continue

                    except Exception as e:
                        self.error_log.append(f"H4-{stock}-H{H}: {e}")
                        continue

            except Exception as e:
                self.error_log.append(f"H4-{stock}: {e}")
                continue

        self.h4_results = h4_results
        print(f"âœ… H4å‡è®¾å®Œæˆ: {len(h4_results)} ä¸ªå®éªŒ (å«åˆ†å±‚å’Œå¤šæ¨¡å‹å¯¹æ¯”)")
        return len(h4_results) > 0

    def create_plot1_h1h2_results(self):
        """å›¾è¡¨1: H1å’ŒH2å‡è®¾ç»“æœ - è‹±æ–‡æ˜¾ç¤º"""
        # æ£€æŸ¥æ˜¯å¦æœ‰çœŸå®æ•°æ®
        if not self.h1_results and not self.h2_results:
            print("âš ï¸ è·³è¿‡å›¾è¡¨1: æ— H1å’ŒH2çœŸå®æ•°æ®")
            return

        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('H1-H2 Hypothesis Research Results', fontsize=16, fontweight='bold')

        # H1: æ¨¡å‹å¯¹æ¯”
        if self.h1_results:
            h1_df = pd.DataFrame(self.h1_results)
            h1_overall = h1_df[h1_df['Regime'] == 'Overall']
            if not h1_overall.empty:
                model_performance = h1_overall.groupby('Model')['R2'].agg(['mean', 'std', 'count'])

                bars = axes[0, 0].bar(model_performance.index, model_performance['mean'],
                                      yerr=model_performance['std'], capsize=5, alpha=0.7,
                                      color=['#FF6B6B', '#4ECDC4', '#45B7D1'])
                axes[0, 0].set_title('H1: Model RÂ² Performance Comparison', fontweight='bold')
                axes[0, 0].set_ylabel('RÂ² Score')
                axes[0, 0].grid(True, alpha=0.3)

                for bar, mean_val, count in zip(bars, model_performance['mean'], model_performance['count']):
                    axes[0, 0].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,
                                    f'{mean_val:.3f}\n(n={count})', ha='center', va='bottom', fontsize=10)
            else:
                axes[0, 0].text(0.5, 0.5, 'No H1 Data Available', ha='center', va='center',
                                transform=axes[0, 0].transAxes)
        else:
            axes[0, 0].text(0.5, 0.5, 'No H1 Data Available', ha='center', va='center', transform=axes[0, 0].transAxes)

        # H1: æ–¹å‘å‡†ç¡®ç‡
        if self.h1_results:
            h1_df = pd.DataFrame(self.h1_results)
            h1_overall = h1_df[h1_df['Regime'] == 'Overall']
            if not h1_overall.empty:
                direction_perf = h1_overall.groupby('Model')['Direction_Accuracy'].mean()
                bars = axes[0, 1].bar(direction_perf.index, direction_perf.values, alpha=0.7,
                                      color=['#FF6B6B', '#4ECDC4', '#45B7D1'])
                axes[0, 1].set_title('H1: Direction Prediction Accuracy', fontweight='bold')
                axes[0, 1].set_ylabel('Accuracy')
                axes[0, 1].axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='Random Level')
                axes[0, 1].legend()
                axes[0, 1].grid(True, alpha=0.3)

                for bar, acc in zip(bars, direction_perf.values):
                    axes[0, 1].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.005,
                                    f'{acc:.3f}', ha='center', va='bottom', fontsize=10)
            else:
                axes[0, 1].text(0.5, 0.5, 'No H1 Direction Data', ha='center', va='center',
                                transform=axes[0, 1].transAxes)
        else:
            axes[0, 1].text(0.5, 0.5, 'No H1 Direction Data', ha='center', va='center', transform=axes[0, 1].transAxes)

        # H2: Feature engineeringå¯¹æ¯”
        if self.h2_results:
            h2_df = pd.DataFrame(self.h2_results)
            feature_performance = h2_df.groupby('FeatureSet')['R2'].agg(['mean', 'std'])

            bars = axes[1, 0].bar(feature_performance.index, feature_performance['mean'],
                                  yerr=feature_performance['std'], capsize=5, alpha=0.7,
                                  color=['#FFA07A', '#98FB98', '#87CEEB'])
            axes[1, 0].set_title('H2: Feature Set RÂ² Performance Comparison', fontweight='bold')
            axes[1, 0].set_ylabel('RÂ² Score')
            axes[1, 0].tick_params(axis='x', rotation=15)
            axes[1, 0].grid(True, alpha=0.3)

            for bar, mean_val in zip(bars, feature_performance['mean']):
                axes[1, 0].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.005,
                                f'{mean_val:.3f}', ha='center', va='bottom', fontsize=10)
        else:
            axes[1, 0].text(0.5, 0.5, 'No H2 Data Available', ha='center', va='center', transform=axes[1, 0].transAxes)

        # H2: ç‰¹å¾æ•°é‡vsæ€§èƒ½
        if self.h2_results:
            h2_df = pd.DataFrame(self.h2_results)
            feature_count_perf = h2_df.groupby('FeatureCount')['R2'].mean().reset_index()
            if not feature_count_perf.empty:
                axes[1, 1].scatter(feature_count_perf['FeatureCount'], feature_count_perf['R2'],
                                   s=100, alpha=0.7, color='purple')
                axes[1, 1].plot(feature_count_perf['FeatureCount'], feature_count_perf['R2'],
                                color='purple', alpha=0.5)
                axes[1, 1].set_title('H2: Feature Count vs Prediction Performance', fontweight='bold')
                axes[1, 1].set_xlabel('Number of Features')
                axes[1, 1].set_ylabel('RÂ² Score')
                axes[1, 1].grid(True, alpha=0.3)
            else:
                axes[1, 1].text(0.5, 0.5, 'Insufficient Feature Data', ha='center', va='center',
                                transform=axes[1, 1].transAxes)
        else:
            axes[1, 1].text(0.5, 0.5, 'No H2 Feature Data', ha='center', va='center', transform=axes[1, 1].transAxes)

        plt.tight_layout()
        filename1 = f'{desktop_path}/01_H1H2_hypothesis_results.png'
        plt.savefig(filename1, dpi=300, bbox_inches='tight')
        plt.close()
        self.figures_saved.append(filename1)

    def create_plot2_h3h4_results(self):
        """å›¾è¡¨2: H3å’ŒH4å‡è®¾ç»“æœ - è‹±æ–‡æ˜¾ç¤º - å¢å¼ºH4å¤šæ¨¡å‹å±•ç¤º"""
        # æ£€æŸ¥æ˜¯å¦æœ‰çœŸå®æ•°æ®
        if not self.h3_results and not self.h4_results:
            print("âš ï¸ è·³è¿‡å›¾è¡¨2: æ— H3å’ŒH4çœŸå®æ•°æ®")
            return

        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('H3-H4 Hypothesis Research Results (Enhanced with H4 Multi-Model)', fontsize=16, fontweight='bold')

        # H3: OBVè´¡çŒ®å¯¹æ¯”
        if self.h3_results:
            h3_df = pd.DataFrame(self.h3_results)
            obv_performance = h3_df.groupby('OBV_Flag')['R2'].agg(['mean', 'std'])

            bars = axes[0, 0].bar(obv_performance.index, obv_performance['mean'],
                                  yerr=obv_performance['std'], capsize=5, alpha=0.7,
                                  color=['#FF69B4', '#32CD32'])
            axes[0, 0].set_title('H3: OBV Indicator Contribution Analysis', fontweight='bold')
            axes[0, 0].set_ylabel('RÂ² Score')
            axes[0, 0].grid(True, alpha=0.3)

            for bar, mean_val in zip(bars, obv_performance['mean']):
                axes[0, 0].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.005,
                                f'{mean_val:.3f}', ha='center', va='bottom', fontsize=10)
        else:
            axes[0, 0].text(0.5, 0.5, 'No H3 Data Available', ha='center', va='center', transform=axes[0, 0].transAxes)

        # H4: ğŸ”¥æ–°å¢ - ä¸åŒæ¨¡å‹åœ¨å„Predictionçª—å£çš„è¡¨ç°å¯¹æ¯”
        if self.h4_results:
            h4_df = pd.DataFrame(self.h4_results)
            h4_overall = h4_df[h4_df['Regime'] == 'Overall']
            if not h4_overall.empty and 'Model' in h4_overall.columns:
                # æ¨¡å‹ x Predictionçª—å£ æ€§èƒ½çŸ©é˜µ
                model_horizon_perf = h4_overall.groupby(['Model', 'Horizon_H'])['R2'].mean().unstack()
                if not model_horizon_perf.empty:
                    model_horizon_perf.plot(kind='bar', ax=axes[0, 1], alpha=0.8)
                    axes[0, 1].set_title('H4: Multi-Model Performance by Forecast Horizon', fontweight='bold')
                    axes[0, 1].set_xlabel('Model Type')
                    axes[0, 1].set_ylabel('RÂ² Score')
                    axes[0, 1].legend(title='Horizon (Days)', bbox_to_anchor=(1.05, 1), loc='upper left')
                    axes[0, 1].grid(True, alpha=0.3)
                    axes[0, 1].tick_params(axis='x', rotation=45)
                else:
                    axes[0, 1].text(0.5, 0.5, 'Insufficient H4 Model-Horizon Data', ha='center', va='center',
                                    transform=axes[0, 1].transAxes)
            else:
                axes[0, 1].text(0.5, 0.5, 'No H4 Model Data', ha='center', va='center', transform=axes[0, 1].transAxes)
        else:
            axes[0, 1].text(0.5, 0.5, 'No H4 Data Available', ha='center', va='center', transform=axes[0, 1].transAxes)

        # H4: Predictionçª—å£å¯¹æ¯” (æ‰€æœ‰æ¨¡å‹å¹³å‡)
        if self.h4_results:
            h4_df = pd.DataFrame(self.h4_results)
            h4_overall = h4_df[h4_df['Regime'] == 'Overall']
            if not h4_overall.empty:
                horizon_performance = h4_overall.groupby('Horizon_H')['R2'].agg(['mean', 'std'])

                axes[1, 0].plot(horizon_performance.index, horizon_performance['mean'],
                                'o-', linewidth=2, markersize=8, color='red')
                axes[1, 0].fill_between(horizon_performance.index,
                                        horizon_performance['mean'] - horizon_performance['std'],
                                        horizon_performance['mean'] + horizon_performance['std'],
                                        alpha=0.3, color='red')
                axes[1, 0].set_title('H4: Forecast Horizon vs Performance (All Models Avg)', fontweight='bold')
                axes[1, 0].set_xlabel('Forecast Horizon H (Days)')
                axes[1, 0].set_ylabel('RÂ² Score')
                axes[1, 0].grid(True, alpha=0.3)

                for h, mean_val in zip(horizon_performance.index, horizon_performance['mean']):
                    axes[1, 0].text(h, mean_val + 0.01, f'{mean_val:.3f}', ha='center', va='bottom')
            else:
                axes[1, 0].text(0.5, 0.5, 'No H4 Overall Data', ha='center', va='center',
                                transform=axes[1, 0].transAxes)
        else:
            axes[1, 0].text(0.5, 0.5, 'No H4 Data Available', ha='center', va='center', transform=axes[1, 0].transAxes)

        # H4: ğŸ”¥æ–°å¢ - æ¨¡å‹å¯¹æ¯”ï¼ˆæ‰€æœ‰çª—å£å¹³å‡ï¼‰
        if self.h4_results:
            h4_df = pd.DataFrame(self.h4_results)
            h4_overall = h4_df[h4_df['Regime'] == 'Overall']
            if not h4_overall.empty and 'Model' in h4_overall.columns:
                model_perf = h4_overall.groupby('Model')['R2'].agg(['mean', 'std'])
                if not model_perf.empty:
                    bars = axes[1, 1].bar(model_perf.index, model_perf['mean'],
                                          yerr=model_perf['std'], capsize=5, alpha=0.7,
                                          color=['#FF6B6B', '#4ECDC4', '#45B7D1'])
                    axes[1, 1].set_title('H4: Model Comparison (All Horizons Avg)', fontweight='bold')
                    axes[1, 1].set_ylabel('Average RÂ² Score')
                    axes[1, 1].grid(True, alpha=0.3)

                    for bar, mean_val, count in zip(bars, model_perf['mean'],
                                                    [len(h4_overall[h4_overall['Model'] == m]) for m in
                                                     model_perf.index]):
                        axes[1, 1].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.005,
                                        f'{mean_val:.3f}\n(n={count})', ha='center', va='bottom', fontsize=10)
                else:
                    axes[1, 1].text(0.5, 0.5, 'Insufficient H4 Model Data', ha='center', va='center',
                                    transform=axes[1, 1].transAxes)
            else:
                axes[1, 1].text(0.5, 0.5, 'No H4 Model Comparison Data', ha='center', va='center',
                                transform=axes[1, 1].transAxes)
        else:
            axes[1, 1].text(0.5, 0.5, 'No H4 Model Data', ha='center', va='center', transform=axes[1, 1].transAxes)

        plt.tight_layout()
        filename2 = f'{desktop_path}/02_H3H4_hypothesis_results_enhanced.png'
        plt.savefig(filename2, dpi=300, bbox_inches='tight')
        plt.close()
        self.figures_saved.append(filename2)

    def create_plot3_market_regime_analysis(self):
        """å›¾è¡¨3: å¸‚åœºçŠ¶æ€åˆ†å±‚åˆ†æ - è‹±æ–‡æ˜¾ç¤º"""
        # æ”¶é›†åˆ†å±‚ç»“æœ
        regime_results = []
        for result in self.h1_results + self.h4_results:
            if 'Regime' in result and result['Regime'] != 'Overall':
                regime_results.append(result)

        # å¦‚æœæ²¡æœ‰çœŸå®åˆ†å±‚ç»“æœï¼Œè·³è¿‡æ­¤å›¾è¡¨
        if not regime_results:
            print("âš ï¸ è·³è¿‡å›¾è¡¨3: æ— çœŸå®å¸‚åœºåˆ†å±‚æ•°æ®")
            return

        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('Market Regime Stratification Analysis Results', fontsize=16, fontweight='bold')

        regime_df = pd.DataFrame(regime_results)

        # 1. ä¸åŒå¸‚åœºçŠ¶æ€çš„æ•´ä½“æ€§èƒ½
        regime_perf = regime_df.groupby('Regime')['R2'].agg(['mean', 'std', 'count'])
        bars = axes[0, 0].bar(regime_perf.index, regime_perf['mean'],
                              yerr=regime_perf['std'], capsize=5, alpha=0.7,
                              color=['#FFB6C1', '#98FB98', '#87CEEB'])
        axes[0, 0].set_title('Overall Performance by Market Regime', fontweight='bold')
        axes[0, 0].set_ylabel('Average RÂ² Score')
        axes[0, 0].grid(True, alpha=0.3)

        for bar, mean_val, count in zip(bars, regime_perf['mean'], regime_perf['count']):
            axes[0, 0].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,
                            f'{mean_val:.3f}\n(n={count})', ha='center', va='bottom', fontsize=10)

        # 2. H1æ¨¡å‹åœ¨ä¸åŒå¸‚åœºçŠ¶æ€ä¸‹çš„è¡¨ç°
        h1_regime = regime_df[regime_df['Hypothesis'] == 'H1']
        if not h1_regime.empty and 'Model' in h1_regime.columns:
            model_regime_perf = h1_regime.groupby(['Model', 'Regime'])['R2'].mean().unstack()
            if not model_regime_perf.empty:
                model_regime_perf.plot(kind='bar', ax=axes[0, 1], alpha=0.7)
                axes[0, 1].set_title('H1: Model Performance by Market Regime', fontweight='bold')
                axes[0, 1].set_ylabel('RÂ² Score')
                axes[0, 1].legend(title='Market Regime')
                axes[0, 1].grid(True, alpha=0.3)
                axes[0, 1].tick_params(axis='x', rotation=45)
            else:
                axes[0, 1].text(0.5, 0.5, 'No H1 Regime Data', ha='center', va='center', transform=axes[0, 1].transAxes)
        else:
            axes[0, 1].text(0.5, 0.5, 'No H1 Regime Data', ha='center', va='center', transform=axes[0, 1].transAxes)

        # 3. H4Predictionçª—å£åœ¨ä¸åŒå¸‚åœºçŠ¶æ€ä¸‹çš„è¡¨ç°
        h4_regime = regime_df[regime_df['Hypothesis'] == 'H4']
        if not h4_regime.empty and 'Horizon_H' in h4_regime.columns:
            horizon_regime_perf = h4_regime.groupby(['Horizon_H', 'Regime'])['R2'].mean().unstack()
            if not horizon_regime_perf.empty:
                horizon_regime_perf.plot(kind='line', ax=axes[1, 0], marker='o')
                axes[1, 0].set_title('H4: Forecast Horizon Performance by Market Regime', fontweight='bold')
                axes[1, 0].set_xlabel('Forecast Horizon H (Days)')
                axes[1, 0].set_ylabel('RÂ² Score')
                axes[1, 0].legend(title='Market Regime')
                axes[1, 0].grid(True, alpha=0.3)
            else:
                axes[1, 0].text(0.5, 0.5, 'No H4 Regime Data', ha='center', va='center', transform=axes[1, 0].transAxes)
        else:
            axes[1, 0].text(0.5, 0.5, 'No H4 Regime Data', ha='center', va='center', transform=axes[1, 0].transAxes)

        # 4. å¸‚åœºçŠ¶æ€ç¨³å®šæ€§åˆ†æ
        regime_stability = regime_df.groupby('Regime')['R2'].std()
        bars = axes[1, 1].bar(regime_stability.index, regime_stability.values, alpha=0.7,
                              color=['#FFB6C1', '#98FB98', '#87CEEB'])
        axes[1, 1].set_title('Market Regime Prediction Stability', fontweight='bold')
        axes[1, 1].set_ylabel('RÂ² Standard Deviation (Stability Index)')
        axes[1, 1].grid(True, alpha=0.3)

        for bar, std_val in zip(bars, regime_stability.values):
            axes[1, 1].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.005,
                            f'{std_val:.3f}', ha='center', va='bottom', fontsize=10)

        plt.tight_layout()
        filename3 = f'{desktop_path}/03_market_regime_analysis.png'
        plt.savefig(filename3, dpi=300, bbox_inches='tight')
        plt.close()
        self.figures_saved.append(filename3)

    def create_plot4_feature_importance(self):
        """å›¾è¡¨4: ç‰¹å¾é‡è¦æ€§åˆ†æ - è‹±æ–‡æ˜¾ç¤º"""
        # æ£€æŸ¥æ˜¯å¦æœ‰çœŸå®çš„ç‰¹å¾é‡è¦æ€§æ•°æ®æˆ–Predictionç¤ºä¾‹
        if not self.feature_importance_data and not self.prediction_examples:
            print("âš ï¸ è·³è¿‡å›¾è¡¨4: æ— ç‰¹å¾é‡è¦æ€§å’ŒPredictionç¤ºä¾‹çœŸå®æ•°æ®")
            return

        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('Feature Importance and Prediction Performance Analysis', fontsize=16, fontweight='bold')

        # 1. ç‰¹å¾é‡è¦æ€§æ’å
        if self.feature_importance_data and 'RF' in self.feature_importance_data:
            feature_names = ['Price', 'Log_Price', 'Return', 'Return_Lag1', 'Return_Lag2',
                             'SMA_15', 'SMA_45', 'RSI', 'MACD', 'MACD_Signal', 'BB_Position',
                             'OBV', 'OBV_MA', 'VFTSE', 'VFTSE_zscore']
            importance_scores = self.feature_importance_data['RF']

            # ç¡®ä¿é•¿åº¦åŒ¹é…
            min_len = min(len(feature_names), len(importance_scores))
            feature_names = feature_names[:min_len]
            importance_scores = importance_scores[:min_len]

            # æ’åº
            sorted_idx = np.argsort(importance_scores)[::-1]
            sorted_features = [feature_names[i] for i in sorted_idx]
            sorted_scores = [importance_scores[i] for i in sorted_idx]

            # åªæ˜¾ç¤ºå‰10ä¸ªæœ€é‡è¦çš„ç‰¹å¾
            top_features = sorted_features[:10]
            top_scores = sorted_scores[:10]

            bars = axes[0, 0].barh(range(len(top_features)), top_scores, alpha=0.7, color='lightgreen')
            axes[0, 0].set_yticks(range(len(top_features)))
            axes[0, 0].set_yticklabels(top_features)
            axes[0, 0].set_xlabel('Importance Score')
            axes[0, 0].set_title('Feature Importance Ranking (Top 10)', fontweight='bold')
            axes[0, 0].grid(True, alpha=0.3)

            for bar, score in zip(bars, top_scores):
                axes[0, 0].text(bar.get_width() + 0.01, bar.get_y() + bar.get_height() / 2,
                                f'{score:.3f}', va='center', fontsize=9)
        else:
            axes[0, 0].text(0.5, 0.5, 'No Feature Importance Data', ha='center', va='center',
                            transform=axes[0, 0].transAxes)

        # 2. Predictionvså®é™…å€¼æ•£ç‚¹å›¾
        if self.prediction_examples and 'y_true' in self.prediction_examples:
            y_true = self.prediction_examples['y_true']
            y_pred = self.prediction_examples['y_pred']
            model_name = self.prediction_examples['model_name']

            axes[0, 1].scatter(y_true, y_pred, alpha=0.6, s=30, color='blue')

            # æ·»åŠ å®Œç¾Predictionçº¿
            min_val = min(y_true.min(), y_pred.min())
            max_val = max(y_true.max(), y_pred.max())
            axes[0, 1].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')

            r2_demo = r2_score(y_true, y_pred)
            axes[0, 1].set_xlabel('Actual Values')
            axes[0, 1].set_ylabel('Predicted Values')
            axes[0, 1].set_title(f'Prediction Performance Example - {model_name} (RÂ²={r2_demo:.3f})', fontweight='bold')
            axes[0, 1].legend()
            axes[0, 1].grid(True, alpha=0.3)
        else:
            axes[0, 1].text(0.5, 0.5, 'No Prediction Example Data', ha='center', va='center',
                            transform=axes[0, 1].transAxes)

        # 3. Predictionæ—¶é—´åºåˆ—
        if self.prediction_examples and 'y_true' in self.prediction_examples:
            y_true = self.prediction_examples['y_true']
            y_pred = self.prediction_examples['y_pred']
            stock_name = self.prediction_examples['stock_name']

            time_points = range(len(y_true))
            axes[1, 0].plot(time_points, y_true, label='Actual Values', linewidth=2, color='blue')
            axes[1, 0].plot(time_points, y_pred, label='Predicted Values', linewidth=2, color='red', alpha=0.7)
            axes[1, 0].fill_between(time_points, y_true, y_pred, alpha=0.3, color='gray')

            axes[1, 0].set_xlabel('Time Points')
            axes[1, 0].set_ylabel('Return Rate')
            axes[1, 0].set_title(f'Time Series Prediction Performance - {stock_name[:10]}', fontweight='bold')
            axes[1, 0].legend()
            axes[1, 0].grid(True, alpha=0.3)
        else:
            axes[1, 0].text(0.5, 0.5, 'No Time Series Data', ha='center', va='center', transform=axes[1, 0].transAxes)

        # 4. è¯¯å·®åˆ†å¸ƒåˆ†æ
        if self.prediction_examples and 'y_true' in self.prediction_examples:
            y_true = self.prediction_examples['y_true']
            y_pred = self.prediction_examples['y_pred']
            errors = y_true - y_pred

            axes[1, 1].hist(errors, bins=20, alpha=0.7, color='orange', edgecolor='black')
            axes[1, 1].axvline(errors.mean(), color='red', linestyle='--', linewidth=2,
                               label=f'Mean: {errors.mean():.4f}')
            axes[1, 1].axvline(0, color='black', linestyle='-', alpha=0.5, label='Zero Error')
            axes[1, 1].set_xlabel('Prediction Error')
            axes[1, 1].set_ylabel('Frequency')
            axes[1, 1].set_title('Prediction Error Distribution', fontweight='bold')
            axes[1, 1].legend()
            axes[1, 1].grid(True, alpha=0.3)
        else:
            axes[1, 1].text(0.5, 0.5, 'No Error Analysis Data', ha='center', va='center',
                            transform=axes[1, 1].transAxes)

        plt.tight_layout()
        filename4 = f'{desktop_path}/04_feature_importance_analysis.png'
        plt.savefig(filename4, dpi=300, bbox_inches='tight')
        plt.close()
        self.figures_saved.append(filename4)

    def create_plot5_comprehensive_summary(self):
        """å›¾è¡¨5: ç»¼åˆåˆ†ææ€»ç»“ - è‹±æ–‡æ˜¾ç¤º"""
        # æ”¶é›†æ‰€æœ‰ç»“æœ
        all_results = []
        if self.h1_results:
            h1_overall = [r for r in self.h1_results if r.get('Regime', 'Overall') == 'Overall']
            for r in h1_overall:
                all_results.append({'Hypothesis': 'H1', 'R2': r['R2'], 'Type': r['Model']})
        if self.h2_results:
            for r in self.h2_results:
                all_results.append({'Hypothesis': 'H2', 'R2': r['R2'], 'Type': r['FeatureSet']})
        if self.h3_results:
            for r in self.h3_results:
                all_results.append({'Hypothesis': 'H3', 'R2': r['R2'], 'Type': r['OBV_Flag']})
        if self.h4_results:
            h4_overall = [r for r in self.h4_results if r.get('Regime', 'Overall') == 'Overall']
            for r in h4_overall:
                all_results.append(
                    {'Hypothesis': 'H4', 'R2': r['R2'], 'Type': f"{r.get('Model', 'Unknown')}_H={r['Horizon_H']}"})

        # å¦‚æœæ²¡æœ‰çœŸå®ç»“æœæ•°æ®ï¼Œè·³è¿‡æ­¤å›¾è¡¨
        if not all_results:
            print("âš ï¸ è·³è¿‡å›¾è¡¨5: æ— çœŸå®å®éªŒç»“æœæ•°æ®")
            return

        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('Comprehensive Analysis Summary', fontsize=16, fontweight='bold')

        all_df = pd.DataFrame(all_results)

        # 1. å››å‡è®¾æ•´ä½“æ€§èƒ½å¯¹æ¯”
        hypothesis_perf = all_df.groupby('Hypothesis')['R2'].agg(['mean', 'std', 'count'])

        bars = axes[0, 0].bar(hypothesis_perf.index, hypothesis_perf['mean'],
                              yerr=hypothesis_perf['std'], capsize=5, alpha=0.7,
                              color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A'])
        axes[0, 0].set_title('Overall Performance Comparison of Four Hypotheses', fontsize=12, fontweight='bold')
        axes[0, 0].set_ylabel('Average RÂ² Score', fontsize=11)
        axes[0, 0].grid(True, alpha=0.3)

        for bar, mean_val, count in zip(bars, hypothesis_perf['mean'], hypothesis_perf['count']):
            axes[0, 0].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,
                            f'{mean_val:.3f}\n(n={count})', ha='center', va='bottom', fontsize=10)

        # 2. æ•°æ®è¦†ç›–åº¦åˆ†æ
        total_stocks = len(self.all_stocks)
        analyzed_stocks = min(50, total_stocks)
        total_experiments = len(self.h1_results) + len(self.h2_results) + len(self.h3_results) + len(self.h4_results)

        coverage_data = [total_stocks, analyzed_stocks, total_experiments]
        coverage_labels = ['Total Stocks', 'Analyzed Stocks', 'Total Experiments']

        bars = axes[0, 1].bar(coverage_labels, coverage_data,
                              color=['skyblue', 'lightgreen', 'coral'], alpha=0.7)
        axes[0, 1].set_title('Data Coverage Analysis', fontsize=12, fontweight='bold')
        axes[0, 1].set_ylabel('Count', fontsize=11)
        axes[0, 1].grid(True, alpha=0.3)

        for bar, value in zip(bars, coverage_data):
            axes[0, 1].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 10,
                            str(value), ha='center', va='bottom', fontweight='bold')

        # 3. RÂ²åˆ†å¸ƒç›´æ–¹å›¾
        all_r2_values = [r['R2'] for r in all_results]

        axes[1, 0].hist(all_r2_values, bins=30, alpha=0.7, color='purple', edgecolor='black')
        axes[1, 0].set_title('RÂ² Distribution of All Experiments', fontsize=12, fontweight='bold')
        axes[1, 0].set_xlabel('RÂ² Score', fontsize=11)
        axes[1, 0].set_ylabel('Frequency', fontsize=11)

        mean_r2 = np.mean(all_r2_values)
        axes[1, 0].axvline(mean_r2, color='red', linestyle='--', linewidth=2,
                           label=f'Mean: {mean_r2:.3f}')
        axes[1, 0].axvline(0, color='black', linestyle='-', alpha=0.5, label='Zero Line')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)

        # 4. ç ”ç©¶æ€»ç»“æ–‡æœ¬ - ä½¿ç”¨è‹±æ–‡é¿å…ä¹±ç 
        axes[1, 1].axis('off')

        total_experiments = len(all_results)
        mean_r2 = np.mean(all_r2_values)
        max_r2 = np.max(all_r2_values)
        success_ratio = len([r for r in all_r2_values if r > 0]) / len(all_r2_values) * 100

        summary_text = f"""H1-H4 Hypothesis Research Summary
====================
Experiment Scale:
- Total Stocks: {len(self.all_stocks)}
- H1 Experiments: {len(self.h1_results)}
- H2 Experiments: {len(self.h2_results)}
- H3 Experiments: {len(self.h3_results)}
- H4 Experiments: {len(self.h4_results)}
- Total Experiments: {total_experiments}

Key Findings:
- Average RÂ²: {mean_r2:.4f}
- Best RÂ²: {max_r2:.4f}
- Success Rate: {success_ratio:.1f}%
- Total Errors: {len(self.error_log)}

Hypothesis Validation:
âœ“ H1: Model Comparison + Market Regime
âœ“ H2: Feature Engineering
âœ“ H3: OBV Contribution Analysis
âœ“ H4: Multi-Model Forecast Horizon + Market Regime
âœ“ Feature Importance Analysis
âœ“ Prediction Visualization

ğŸ”¥ Enhanced H4 Features:
âœ“ SVR vs RF vs LSTM Comparison
âœ“ Multi-Horizon Analysis
âœ“ Market Regime Stratification"""

        axes[1, 1].text(0.05, 0.95, summary_text, transform=axes[1, 1].transAxes, fontsize=9,
                        verticalalignment='top', fontfamily='monospace',
                        bbox=dict(boxstyle='round', facecolor='lightcyan', alpha=0.8))

        plt.tight_layout()
        filename5 = f'{desktop_path}/05_comprehensive_summary.png'
        plt.savefig(filename5, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')
        plt.close()
        self.figures_saved.append(filename5)

    def create_plot6_h4_detailed_analysis(self):
        """å›¾è¡¨6: H4å‡è®¾è¯¦ç»†åˆ†æ - ä¸“é—¨å±•ç¤ºSVRã€RFã€LSTMåœ¨ä¸åŒPredictionçª—å£çš„è¡¨ç°"""
        if not self.h4_results:
            print("âš ï¸ è·³è¿‡å›¾è¡¨6: æ— H4è¯¦ç»†æ•°æ®")
            return

        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('H4 Detailed Analysis: SVR vs RF vs LSTM across Forecast Horizons', fontsize=16, fontweight='bold')

        h4_df = pd.DataFrame(self.h4_results)
        h4_overall = h4_df[h4_df['Regime'] == 'Overall']

        if h4_overall.empty:
            for i, ax in enumerate(axes.flat):
                ax.text(0.5, 0.5, 'No H4 Detailed Data', ha='center', va='center', transform=ax.transAxes)
            plt.tight_layout()
            filename6 = f'{desktop_path}/06_h4_detailed_analysis.png'
            plt.savefig(filename6, dpi=300, bbox_inches='tight')
            plt.close()
            self.figures_saved.append(filename6)
            return

        # 1. çƒ­å›¾ï¼šæ¨¡å‹ x Predictionçª—å£ æ€§èƒ½çŸ©é˜µ
        if 'Model' in h4_overall.columns:
            pivot_data = h4_overall.pivot_table(values='R2', index='Model', columns='Horizon_H', aggfunc='mean')
            if not pivot_data.empty:
                sns.heatmap(pivot_data, annot=True, fmt='.3f', cmap='RdYlBu_r', ax=axes[0, 0],
                            cbar_kws={'label': 'RÂ² Score'})
                axes[0, 0].set_title('Performance Heatmap: Model Ã— Forecast Horizon', fontweight='bold')
                axes[0, 0].set_xlabel('Forecast Horizon H (Days)')
                axes[0, 0].set_ylabel('Model Type')
            else:
                axes[0, 0].text(0.5, 0.5, 'No Pivot Data', ha='center', va='center', transform=axes[0, 0].transAxes)
        else:
            axes[0, 0].text(0.5, 0.5, 'No Model Column', ha='center', va='center', transform=axes[0, 0].transAxes)

        # 2. çº¿å›¾ï¼šæ¯ä¸ªæ¨¡å‹åœ¨ä¸åŒPredictionçª—å£çš„è¡¨ç°è¶‹åŠ¿
        if 'Model' in h4_overall.columns:
            for model in h4_overall['Model'].unique():
                model_data = h4_overall[h4_overall['Model'] == model]
                horizon_perf = model_data.groupby('Horizon_H')['R2'].mean()
                axes[0, 1].plot(horizon_perf.index, horizon_perf.values, 'o-', label=model, linewidth=2, markersize=6)

            axes[0, 1].set_title('Model Performance Trends by Forecast Horizon', fontweight='bold')
            axes[0, 1].set_xlabel('Forecast Horizon H (Days)')
            axes[0, 1].set_ylabel('RÂ² Score')
            axes[0, 1].legend()
            axes[0, 1].grid(True, alpha=0.3)
        else:
            axes[0, 1].text(0.5, 0.5, 'No Model Trend Data', ha='center', va='center', transform=axes[0, 1].transAxes)

        # 3. ç®±çº¿å›¾ï¼šä¸åŒæ¨¡å‹çš„RÂ²åˆ†å¸ƒ
        if 'Model' in h4_overall.columns:
            models_data = []
            labels = []
            for model in h4_overall['Model'].unique():
                model_r2 = h4_overall[h4_overall['Model'] == model]['R2']
                models_data.append(model_r2)
                labels.append(model)

            if models_data:
                axes[1, 0].boxplot(models_data, labels=labels, patch_artist=True)
                axes[1, 0].set_title('RÂ² Score Distribution by Model', fontweight='bold')
                axes[1, 0].set_ylabel('RÂ² Score')
                axes[1, 0].grid(True, alpha=0.3)
            else:
                axes[1, 0].text(0.5, 0.5, 'No Distribution Data', ha='center', va='center',
                                transform=axes[1, 0].transAxes)
        else:
            axes[1, 0].text(0.5, 0.5, 'No Model Distribution Data', ha='center', va='center',
                            transform=axes[1, 0].transAxes)

        # 4. ç»Ÿè®¡è¡¨ï¼šæ¨¡å‹æ€§èƒ½è¯¦ç»†å¯¹æ¯”
        axes[1, 1].axis('off')
        if 'Model' in h4_overall.columns:
            model_stats = h4_overall.groupby('Model')['R2'].agg(['mean', 'std', 'min', 'max', 'count'])

            table_text = "Model Performance Statistics\n" + "=" * 40 + "\n"
            for model in model_stats.index:
                stats = model_stats.loc[model]
                table_text += f"{model}:\n"
                table_text += f"  Mean RÂ²: {stats['mean']:.4f}\n"
                table_text += f"  Std Dev: {stats['std']:.4f}\n"
                table_text += f"  Min RÂ²:  {stats['min']:.4f}\n"
                table_text += f"  Max RÂ²:  {stats['max']:.4f}\n"
                table_text += f"  Count:   {int(stats['count'])}\n\n"

            # æ·»åŠ æœ€ä½³ç»„åˆ
            best_combo = h4_overall.loc[h4_overall['R2'].idxmax()]
            table_text += "Best Performance:\n"
            table_text += f"  Model: {best_combo.get('Model', 'Unknown')}\n"
            table_text += f"  Horizon: {best_combo['Horizon_H']} days\n"
            table_text += f"  RÂ²: {best_combo['R2']:.4f}\n"

            axes[1, 1].text(0.05, 0.95, table_text, transform=axes[1, 1].transAxes, fontsize=10,
                            verticalalignment='top', fontfamily='monospace',
                            bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))
        else:
            axes[1, 1].text(0.5, 0.5, 'No Model Statistics', ha='center', va='center', transform=axes[1, 1].transAxes)

        plt.tight_layout()
        filename6 = f'{desktop_path}/06_h4_detailed_analysis.png'
        plt.savefig(filename6, dpi=300, bbox_inches='tight')
        plt.close()
        self.figures_saved.append(filename6)

    def create_plot7_technical_indicators(self):
        """å›¾è¡¨7: æŠ€æœ¯æŒ‡æ ‡åˆ†æ - è‹±æ–‡æ˜¾ç¤º"""
        # æ£€æŸ¥æ˜¯å¦æœ‰çœŸå®è‚¡ç¥¨æ•°æ®
        if not self.all_stocks or len(self.all_stocks) == 0:
            print("âš ï¸ è·³è¿‡å›¾è¡¨7: æ— çœŸå®è‚¡ç¥¨æ•°æ®")
            return

        # ä½¿ç”¨ç¬¬ä¸€åªè‚¡ç¥¨ä½œä¸ºç¤ºä¾‹
        sample_stock = self.all_stocks[0]
        prices = self.data[sample_stock].dropna().values

        # æ£€æŸ¥ä»·æ ¼æ•°æ®æ˜¯å¦è¶³å¤Ÿ
        if len(prices) < 50:
            print("âš ï¸ è·³è¿‡å›¾è¡¨7: è‚¡ç¥¨ä»·æ ¼æ•°æ®ä¸è¶³")
            return

        # å–å‰200ä¸ªç‚¹ç”¨äºåˆ†æ
        prices = prices[:200] if len(prices) > 200 else prices

        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('Technical Indicators In-depth Analysis', fontsize=16, fontweight='bold')

        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        price_series = pd.Series(prices)

        # 1. ä»·æ ¼ä¸ç§»åŠ¨å¹³å‡çº¿
        sma_15 = price_series.rolling(window=15, min_periods=1).mean()
        sma_45 = price_series.rolling(window=45, min_periods=1).mean()

        time_points = range(len(prices))
        axes[0, 0].plot(time_points, prices, label='Price', linewidth=1.5, color='blue')
        axes[0, 0].plot(time_points, sma_15, label='SMA15', linewidth=1.5, color='red')
        axes[0, 0].plot(time_points, sma_45, label='SMA45', linewidth=1.5, color='green')
        axes[0, 0].set_title(f'Price and Moving Averages - {sample_stock[:10]}', fontweight='bold')
        axes[0, 0].set_xlabel('Time Points')
        axes[0, 0].set_ylabel('Price')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)

        # 2. RSIæŒ‡æ ‡
        delta = price_series.diff()
        gain = delta.where(delta > 0, 0).rolling(window=14, min_periods=1).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14, min_periods=1).mean()
        rs = gain / (loss + 1e-8)
        rsi = 100 - (100 / (1 + rs))

        axes[0, 1].plot(time_points, rsi, linewidth=1.5, color='purple')
        axes[0, 1].axhline(y=70, color='red', linestyle='--', alpha=0.7, label='Overbought (70)')
        axes[0, 1].axhline(y=30, color='green', linestyle='--', alpha=0.7, label='Oversold (30)')
        axes[0, 1].set_title('RSI Relative Strength Index', fontweight='bold')
        axes[0, 1].set_xlabel('Time Points')
        axes[0, 1].set_ylabel('RSI Value')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)

        # 3. MACDæŒ‡æ ‡
        ema_12 = price_series.ewm(span=12, min_periods=1).mean()
        ema_26 = price_series.ewm(span=26, min_periods=1).mean()
        macd = ema_12 - ema_26
        macd_signal = macd.ewm(span=9, min_periods=1).mean()
        macd_histogram = macd - macd_signal

        axes[1, 0].plot(time_points, macd, label='MACD', linewidth=1.5, color='blue')
        axes[1, 0].plot(time_points, macd_signal, label='MACD Signal', linewidth=1.5, color='red')
        axes[1, 0].bar(time_points, macd_histogram, alpha=0.3, color='gray', label='MACD Histogram')
        axes[1, 0].axhline(y=0, color='black', linestyle='-', alpha=0.5)
        axes[1, 0].set_title('MACD Indicator Analysis', fontweight='bold')
        axes[1, 0].set_xlabel('Time Points')
        axes[1, 0].set_ylabel('MACD Value')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)

        # 4. å¸ƒæ—å¸¦
        bb_middle = price_series.rolling(window=20, min_periods=1).mean()
        bb_std = price_series.rolling(window=20, min_periods=1).std()
        bb_upper = bb_middle + (bb_std * 2)
        bb_lower = bb_middle - (bb_std * 2)

        axes[1, 1].plot(time_points, prices, label='Price', linewidth=1.5, color='blue')
        axes[1, 1].plot(time_points, bb_upper, label='Bollinger Upper', linewidth=1, color='red', linestyle='--')
        axes[1, 1].plot(time_points, bb_middle, label='Bollinger Middle', linewidth=1, color='orange')
        axes[1, 1].plot(time_points, bb_lower, label='Bollinger Lower', linewidth=1, color='green', linestyle='--')
        axes[1, 1].fill_between(time_points, bb_lower, bb_upper, alpha=0.1, color='gray')
        axes[1, 1].set_title('Bollinger Bands Indicator', fontweight='bold')
        axes[1, 1].set_xlabel('Time Points')
        axes[1, 1].set_ylabel('Price')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)

        plt.tight_layout()
        filename7 = f'{desktop_path}/07_technical_indicators_analysis.png'
        plt.savefig(filename7, dpi=300, bbox_inches='tight')
        plt.close()
        self.figures_saved.append(filename7)

    def create_all_plots(self):
        """åˆ›å»ºæ‰€æœ‰æœ‰çœŸå®æ•°æ®çš„å›¾è¡¨"""
        print(f"\nğŸ“Š ç”Ÿæˆæœ‰çœŸå®æ•°æ®çš„H1-H4å‡è®¾åˆ†æå›¾è¡¨...")

        # æµ‹è¯•ä¸­æ–‡å­—ä½“
        try:
            plt.figure(figsize=(6, 4))
            plt.text(0.5, 0.5, 'ä¸­æ–‡å­—ä½“æµ‹è¯•', ha='center', va='center', fontsize=16)
            plt.title('å­—ä½“æµ‹è¯•')
            test_filename = f'{desktop_path}/font_test.png'
            plt.savefig(test_filename, dpi=150, bbox_inches='tight')
            plt.close()
            os.remove(test_filename)  # åˆ é™¤æµ‹è¯•æ–‡ä»¶
            print("âœ… ä¸­æ–‡å­—ä½“è®¾ç½®æ­£å¸¸")
        except Exception as e:
            print(f"âš ï¸ ä¸­æ–‡å­—ä½“å¯èƒ½æœ‰é—®é¢˜: {e}")

        # åˆ›å»ºå›¾è¡¨ï¼ˆåªç”Ÿæˆæœ‰çœŸå®æ•°æ®çš„ï¼‰

        # å›¾è¡¨1: H1H2ç»“æœ - æ€»æ˜¯ç”Ÿæˆï¼Œå› ä¸ºåŸºäºåŸºç¡€å®éªŒç»“æœ
        try:
            self.create_plot1_h1h2_results()
            print("âœ… å›¾è¡¨1: H1-H2å‡è®¾ç»“æœ")
        except Exception as e:
            print(f"âš ï¸ å›¾è¡¨1ç”Ÿæˆå¤±è´¥: {e}")

        # å›¾è¡¨2: H3H4ç»“æœ - æ€»æ˜¯ç”Ÿæˆï¼Œå› ä¸ºåŸºäºåŸºç¡€å®éªŒç»“æœ
        try:
            self.create_plot2_h3h4_results()
            print("âœ… å›¾è¡¨2: H3-H4å‡è®¾ç»“æœ (å¢å¼ºç‰ˆ)")
        except Exception as e:
            print(f"âš ï¸ å›¾è¡¨2ç”Ÿæˆå¤±è´¥: {e}")

        # å›¾è¡¨3: å¸‚åœºçŠ¶æ€åˆ†å±‚ - åªæœ‰çœŸå®åˆ†å±‚æ•°æ®æ—¶æ‰ç”Ÿæˆ
        try:
            self.create_plot3_market_regime_analysis()
            print("âœ… å›¾è¡¨3: å¸‚åœºçŠ¶æ€åˆ†å±‚åˆ†æ")
        except Exception as e:
            print(f"âš ï¸ å›¾è¡¨3è·³è¿‡æˆ–å¤±è´¥: {e}")

        # å›¾è¡¨4: ç‰¹å¾é‡è¦æ€§ - æ€»æ˜¯ç”Ÿæˆï¼ŒåŸºäºå®éªŒä¸­çš„ç‰¹å¾é‡è¦æ€§
        try:
            self.create_plot4_feature_importance()
            print("âœ… å›¾è¡¨4: ç‰¹å¾é‡è¦æ€§åˆ†æ")
        except Exception as e:
            print(f"âš ï¸ å›¾è¡¨4ç”Ÿæˆå¤±è´¥: {e}")

        # å›¾è¡¨5: ç»¼åˆæ€»ç»“ - åªæœ‰å®éªŒç»“æœæ—¶æ‰ç”Ÿæˆ
        try:
            self.create_plot5_comprehensive_summary()
            print("âœ… å›¾è¡¨5: ç»¼åˆåˆ†ææ€»ç»“")
        except Exception as e:
            print(f"âš ï¸ å›¾è¡¨5è·³è¿‡æˆ–å¤±è´¥: {e}")

        # ğŸ”¥ æ–°å¢å›¾è¡¨6: H4è¯¦ç»†åˆ†æ
        try:
            self.create_plot6_h4_detailed_analysis()
            print("âœ… å›¾è¡¨6: H4è¯¦ç»†åˆ†æ (SVR vs RF vs LSTM)")
        except Exception as e:
            print(f"âš ï¸ å›¾è¡¨6ç”Ÿæˆå¤±è´¥: {e}")

        # å›¾è¡¨7: æŠ€æœ¯æŒ‡æ ‡ - åªæœ‰è‚¡ç¥¨æ•°æ®æ—¶æ‰ç”Ÿæˆ
        try:
            if self.all_stocks:
                self.create_plot7_technical_indicators()
                print("âœ… å›¾è¡¨7: æŠ€æœ¯æŒ‡æ ‡åˆ†æ")
            else:
                print("âš ï¸ è·³è¿‡å›¾è¡¨7: æ— è‚¡ç¥¨æ•°æ®")
        except Exception as e:
            print(f"âš ï¸ å›¾è¡¨7ç”Ÿæˆå¤±è´¥: {e}")

        print(f"âœ… ç”Ÿæˆå›¾è¡¨: {len(self.figures_saved)} ä¸ª")
        for fig in self.figures_saved:
            print(f"â”œâ”€ {os.path.basename(fig)}")

    def save_results(self):
        """ä¿å­˜æ‰€æœ‰ç»“æœ"""
        print(f"\nğŸ’¾ ä¿å­˜H1-H4å‡è®¾ç ”ç©¶ç»“æœ...")

        # ä¿å­˜å„å‡è®¾ç»“æœ
        if self.h1_results:
            h1_df = pd.DataFrame(self.h1_results)
            h1_df.to_csv(f'{desktop_path}/H1_model_comparison_results.csv', index=False, encoding='utf-8-sig')
            print(f"âœ… H1ç»“æœ: H1_model_comparison_results.csv")

        if self.h2_results:
            h2_df = pd.DataFrame(self.h2_results)
            h2_df.to_csv(f'{desktop_path}/H2_feature_engineering_results.csv', index=False, encoding='utf-8-sig')
            print(f"âœ… H2ç»“æœ: H2_feature_engineering_results.csv")

        if self.h3_results:
            h3_df = pd.DataFrame(self.h3_results)
            h3_df.to_csv(f'{desktop_path}/H3_obv_contribution_results.csv', index=False, encoding='utf-8-sig')
            print(f"âœ… H3ç»“æœ: H3_obv_contribution_results.csv")

        if self.h4_results:
            h4_df = pd.DataFrame(self.h4_results)
            h4_df.to_csv(f'{desktop_path}/H4_enhanced_forecast_horizon_results.csv', index=False, encoding='utf-8-sig')
            print(f"âœ… H4ç»“æœ: H4_enhanced_forecast_horizon_results.csv (å«å¤šæ¨¡å‹å¯¹æ¯”)")

        # ä¿å­˜é”™è¯¯æ—¥å¿—
        if self.error_log:
            with open(f'{desktop_path}/error_log.txt', 'w', encoding='utf-8') as f:
                f.write('\n'.join(self.error_log))
            print(f"âœ… é”™è¯¯æ—¥å¿—: error_log.txt ({len(self.error_log)} æ¡)")

        # åˆ›å»ºç»¼åˆæŠ¥å‘Š
        total_experiments = len(self.h1_results) + len(self.h2_results) + len(self.h3_results) + len(self.h4_results)

        all_r2_values = []
        for results_list in [self.h1_results, self.h2_results, self.h3_results, self.h4_results]:
            all_r2_values.extend([r['R2'] for r in results_list])

        mean_r2 = np.mean(all_r2_values) if all_r2_values else 0
        max_r2 = np.max(all_r2_values) if all_r2_values else 0

        # ğŸ”¥ H4å¢å¼ºç»Ÿè®¡
        h4_model_stats = []
        if self.h4_results:
            h4_df = pd.DataFrame(self.h4_results)
            if 'Model' in h4_df.columns:
                h4_overall = h4_df[h4_df['Regime'] == 'Overall']
                if not h4_overall.empty:
                    best_combo = h4_overall.loc[h4_overall['R2'].idxmax()]
                    h4_model_stats.append(
                        f"â”œâ”€ H4æœ€ä½³ç»„åˆ: {best_combo.get('Model', 'Unknown')}_H{best_combo['Horizon_H']} (RÂ²={best_combo['R2']:.4f})")

                    model_avg = h4_overall.groupby('Model')['R2'].mean()
                    for model, avg_r2 in model_avg.items():
                        h4_model_stats.append(f"â”œâ”€ H4_{model}å¹³å‡: {avg_r2:.4f}")

        report_lines = [
            "ğŸ”¥ å¢å¼ºç‰ˆH1-H4å‡è®¾è‚¡ç¥¨Predictionç ”ç©¶æŠ¥å‘Š (H4å¤šæ¨¡å‹å¢å¼º)",
            "=" * 80,
            f"ç ”ç©¶æ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"æ•°æ®æ–‡ä»¶: {os.path.basename(data_path)}",
            "",
            "ğŸ“Š ç ”ç©¶å‡è®¾ (å¢å¼ºç‰ˆ):",
            "â”œâ”€ H1: æ¨¡å‹å¯¹æ¯” (SVR vs RF vs LSTM) + å¸‚åœºçŠ¶æ€åˆ†å±‚",
            "â”œâ”€ H2: Feature engineering (ä»·æ ¼ vs ä»·æ ¼+æŠ€æœ¯æŒ‡æ ‡ vs å…¨ç‰¹å¾)",
            "â”œâ”€ H3: OBVè´¡çŒ® (æœ‰OBV vs æ— OBV)",
            "â””â”€ ğŸ”¥ H4å¢å¼º: Predictionçª—å£ Ã— å¤šæ¨¡å‹å¯¹æ¯” Ã— å¸‚åœºåˆ†å±‚ (SVRÃ—RFÃ—LSTM Ã— H=5,10,30,60 Ã— 3å¸‚åœºçŠ¶æ€)",
            "",
            "ğŸ“ˆ å®éªŒè§„æ¨¡:",
            f"â”œâ”€ æ€»è‚¡ç¥¨æ•°: {len(self.all_stocks)}",
            f"â”œâ”€ H1å®éªŒæ•°: {len(self.h1_results)} (å«åˆ†å±‚)",
            f"â”œâ”€ H2å®éªŒæ•°: {len(self.h2_results)}",
            f"â”œâ”€ H3å®éªŒæ•°: {len(self.h3_results)}",
            f"â”œâ”€ ğŸ”¥ H4å¢å¼ºå®éªŒæ•°: {len(self.h4_results)} (å«å¤šæ¨¡å‹Ã—åˆ†å±‚)",
            f"â”œâ”€ æ€»å®éªŒæ•°: {total_experiments}",
            f"â””â”€ é”™è¯¯è®°å½•: {len(self.error_log)} æ¡",
            "",
            "ğŸ¯ ä¸»è¦å‘ç°:",
            f"â”œâ”€ å¹³å‡RÂ²: {mean_r2:.4f}",
            f"â”œâ”€ æœ€ä½³RÂ²: {max_r2:.4f}",
            f"â”œâ”€ æˆåŠŸç‡: {len([r for r in all_r2_values if r > 0]) / len(all_r2_values) * 100:.1f}%" if all_r2_values else "â”œâ”€ æˆåŠŸç‡: N/A"
        ]

        # æ·»åŠ H4ç»Ÿè®¡ä¿¡æ¯
        report_lines.extend(h4_model_stats)

        # ç»§ç»­æ·»åŠ å…¶ä»–å†…å®¹
        report_lines.extend([
            "",
            "ğŸ”§ H4å¢å¼ºå‡çº§:",
            "â”œâ”€ âœ… æ–°å¢SVRæ¨¡å‹åœ¨H4ä¸­çš„å®Œæ•´å¯¹æ¯”",
            "â”œâ”€ âœ… æ–°å¢LSTMæ¨¡å‹åœ¨H4ä¸­çš„å®Œæ•´å¯¹æ¯”",
            "â”œâ”€ âœ… å®ç°Predictionçª—å£Ã—æ¨¡å‹ç±»å‹Ã—å¸‚åœºçŠ¶æ€ä¸‰ç»´åˆ†æ",
            "â”œâ”€ âœ… æ–°å¢H4ä¸“é—¨è¯¦ç»†åˆ†æå›¾è¡¨",
            "â”œâ”€ âœ… å¤šæ¨¡å‹æ€§èƒ½çƒ­å›¾å¯è§†åŒ–",
            "â”œâ”€ âœ… æ¨¡å‹ç¨³å®šæ€§ç®±çº¿å›¾åˆ†æ",
            "â””â”€ âœ… æœ€ä½³æ¨¡å‹-çª—å£ç»„åˆè¯†åˆ«",
            "",
            "ğŸ”§ ç³»ç»Ÿæ€»ä½“å¢å¼º:",
            "â”œâ”€ âœ… ä¿®å¤ä¸­æ–‡å­—ä½“ä¹±ç é—®é¢˜",
            "â”œâ”€ âœ… å¢åŠ æ•°æ®éªŒè¯å’Œç©ºå€¼å¤„ç†",
            "â”œâ”€ âœ… æ–°å¢H4è¯¦ç»†åˆ†æå›¾è¡¨",
            "â”œâ”€ âœ… å®Œå–„ç‰¹å¾é‡è¦æ€§åˆ†æ",
            "â”œâ”€ âœ… å¢å¼ºPredictionæ•ˆæœå¯è§†åŒ–",
            "â””â”€ âœ… å®Œæ•´çš„é”™è¯¯å¤„ç†æœºåˆ¶",
            "",
            "ğŸ“ è¾“å‡ºæ–‡ä»¶:",
            f"â”œâ”€ å›¾è¡¨æ–‡ä»¶: {len(self.figures_saved)} ä¸ª"
        ])

        # æ·»åŠ å›¾è¡¨æ–‡ä»¶ååˆ—è¡¨
        for fig in self.figures_saved:
            report_lines.append(f"â”‚  â”œâ”€ {os.path.basename(fig)}")

        # æ·»åŠ å…¶ä½™æŠ¥å‘Šå†…å®¹
        report_lines.extend([
            f"â”œâ”€ æ•°æ®æ–‡ä»¶: 4 ä¸ª (H1-H4ç»“æœCSV)",
            f"â””â”€ æ—¥å¿—æ–‡ä»¶: 1 ä¸ª (é”™è¯¯æ—¥å¿—)",
            "",
            "ğŸš€ H4å¤šæ¨¡å‹å¢å¼ºä»·å€¼:",
            "âœ… é¦–æ¬¡å®ç°Predictionçª—å£Ã—æ¨¡å‹ç±»å‹Ã—å¸‚åœºçŠ¶æ€ä¸‰ç»´å…¨é¢å¯¹æ¯”",
            "âœ… è¯†åˆ«æœ€ä¼˜æ¨¡å‹-çª—å£-å¸‚åœºçŠ¶æ€ç»„åˆ",
            "âœ… æä¾›å·¥ä¸šçº§å¤šæ¨¡å‹é€‰æ‹©æŒ‡å¯¼",
            "âœ… å®ç°è·¨æ—¶é—´çª—å£çš„æ¨¡å‹ç¨³å®šæ€§åˆ†æ",
            "âœ… ä¸ºå®é™…æŠ•èµ„å†³ç­–æä¾›ç§‘å­¦ä¾æ®",
            "",
            "âœ… ğŸ”¥ H4å¢å¼ºç‰ˆå‡è®¾ç ”ç©¶å®Œæˆ (SVRÃ—RFÃ—LSTMå…¨è¦†ç›–)"
        ])

        # ä¿å­˜æŠ¥å‘Š
        with open(f'{desktop_path}/enhanced_H1H4_research_report_with_h4_multimodel.txt', 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))

        print(f"âœ… ç»¼åˆæŠ¥å‘Š: enhanced_H1H4_research_report_with_h4_multimodel.txt")


def main():
    """ğŸ”¥ å¢å¼ºç‰ˆH1-H4å‡è®¾ç ”ç©¶ä¸»å‡½æ•° (H4å¤šæ¨¡å‹å‡çº§)"""
    print("=" * 90)
    print("   ğŸ”¥ å¢å¼ºç‰ˆH1-H4å‡è®¾è‚¡ç¥¨Predictionç ”ç©¶ç³»ç»Ÿ (H4å¤šæ¨¡å‹å‡çº§ç‰ˆ)")
    print("   Enhanced H1-H4 Hypothesis Research System with H4 Multi-Model")
    print("   H4æ–°å¢: SVR Ã— RF Ã— LSTM å…¨é¢å¯¹æ¯” + Predictionçª—å£åˆ†æ")
    print("=" * 90)

    if data_path is None:
        print(f"âŒ è¯·ç¡®ä¿CSVæ–‡ä»¶å­˜åœ¨äº: {data_folder}")
        return

    # åˆå§‹åŒ–å¢å¼ºç‰ˆç ”ç©¶ç³»ç»Ÿ
    research = EnhancedH1H4ResearchSystem()

    start_time = pd.Timestamp.now()

    try:
        # æ•°æ®åŠ è½½
        print(f"\nğŸ“ æ•°æ®åŠ è½½é˜¶æ®µ")
        if not research.load_stock_data(data_path):
            print("âŒ æ•°æ®åŠ è½½å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
            return

        # è¿›è¡Œå››å‡è®¾ç ”ç©¶
        print(f"\nğŸ”¬ å¼€å§‹H1-H4å‡è®¾éªŒè¯ (H4å¢å¼º: å«SVRÃ—RFÃ—LSTMå¤šæ¨¡å‹å¯¹æ¯”)")

        # H1: æ¨¡å‹å¯¹æ¯” + å¸‚åœºçŠ¶æ€åˆ†å±‚
        print("\n" + "=" * 50)
        research.conduct_h1_hypothesis(sample_stocks=50)

        # H2: Feature engineering
        print("\n" + "=" * 50)
        research.conduct_h2_hypothesis(sample_stocks=30)

        # H3: OBVè´¡çŒ®
        print("\n" + "=" * 50)
        research.conduct_h3_hypothesis(sample_stocks=30)

        # ğŸ”¥ H4: Predictionçª—å£ + å¸‚åœºçŠ¶æ€åˆ†å±‚ + å¤šæ¨¡å‹å¯¹æ¯” (SVR, RF, LSTM)
        print("\n" + "=" * 50)
        print("ğŸ”¥ H4å¢å¼ºç‰ˆ: Predictionçª—å£ Ã— å¤šæ¨¡å‹å¯¹æ¯” Ã— å¸‚åœºåˆ†å±‚")
        research.conduct_h4_hypothesis(sample_stocks=30)

        # ç”Ÿæˆæ‰€æœ‰å›¾è¡¨
        print("\n" + "=" * 50)
        research.create_all_plots()

        # Save results
        print("\n" + "=" * 50)
        research.save_results()

        end_time = pd.Timestamp.now()
        total_time = (end_time - start_time).total_seconds() / 60

        # æœ€ç»ˆæ€»ç»“
        total_experiments = (len(research.h1_results) + len(research.h2_results) +
                             len(research.h3_results) + len(research.h4_results))

        print(f"\n{'=' * 90}")
        print(f"   ğŸ”¥ å¢å¼ºç‰ˆH1-H4å‡è®¾ç ”ç©¶ç³»ç»Ÿè¿è¡Œå®Œæˆ! (H4å¤šæ¨¡å‹å‡çº§ç‰ˆ)")
        print(f"{'=' * 90}")
        print(f"ğŸ† æ‰§è¡Œç»Ÿè®¡:")
        print(f"â”œâ”€ æ€»è€—æ—¶: {total_time:.1f} åˆ†é’Ÿ")
        print(f"â”œâ”€ åˆ†æè‚¡ç¥¨: {len(research.all_stocks)} åª")
        print(f"â”œâ”€ H1å®éªŒæ•°: {len(research.h1_results)} ä¸ª (å«åˆ†å±‚)")
        print(f"â”œâ”€ H2å®éªŒæ•°: {len(research.h2_results)} ä¸ª")
        print(f"â”œâ”€ H3å®éªŒæ•°: {len(research.h3_results)} ä¸ª")
        print(f"â”œâ”€ ğŸ”¥ H4å¢å¼ºå®éªŒæ•°: {len(research.h4_results)} ä¸ª (SVRÃ—RFÃ—LSTMÃ—åˆ†å±‚)")
        print(f"â”œâ”€ æ€»å®éªŒæ•°: {total_experiments} ä¸ª")
        print(f"â”œâ”€ é”™è¯¯è®°å½•: {len(research.error_log)} æ¡")
        print(f"â”œâ”€ ç”Ÿæˆå›¾è¡¨: {len(research.figures_saved)} ä¸ª")
        print(f"â””â”€ ä¿å­˜æ–‡ä»¶: {len(research.figures_saved) + 5} ä¸ª")

        print(f"\nğŸ”¥ H4å¤šæ¨¡å‹å‡çº§äº®ç‚¹:")
        print(f"âœ… SVRæ”¯æŒå‘é‡æœºå›å½’å…¨é¢é›†æˆ")
        print(f"âœ… RFéšæœºæ£®æ—ä¿æŒæœ€å¼ºåŸºå‡†")
        print(f"âœ… LSTM(MLP)ç¥ç»ç½‘ç»œæ·±åº¦å­¦ä¹ ")
        print(f"âœ… 3æ¨¡å‹Ã—4çª—å£Ã—3å¸‚åœºçŠ¶æ€=36ç»´åº¦åˆ†æ")
        print(f"âœ… çƒ­å›¾å¯è§†åŒ–æ¨¡å‹-çª—å£æ€§èƒ½çŸ©é˜µ")
        print(f"âœ… æœ€ä½³ç»„åˆæ™ºèƒ½è¯†åˆ«ç³»ç»Ÿ")

        print(f"\nğŸ”§ ç³»ç»Ÿå¢å¼º:")
        print(f"âœ… ä¿®å¤ä¸­æ–‡å­—ä½“ä¹±ç é—®é¢˜")
        print(f"âœ… è§£å†³å›¾ç‰‡å†…å®¹ç¼ºå¤±é—®é¢˜")
        print(f"âœ… æ–°å¢H4ä¸“é—¨è¯¦ç»†åˆ†æå›¾è¡¨")
        print(f"âœ… å®Œå–„æ•°æ®éªŒè¯æœºåˆ¶")
        print(f"âœ… å¢å¼ºé”™è¯¯å¤„ç†å’Œæ—¥å¿—")

        print(f"\nğŸ›ï¸ å‡è®¾éªŒè¯:")
        print(f"âœ… H1: æ¨¡å‹å¯¹æ¯” + è·¨å¸‚åœºçŠ¶æ€éªŒè¯")
        print(f"âœ… H2: Feature engineeringå®Œæ•´è¯„ä¼°")
        print(f"âœ… H3: OBVæŒ‡æ ‡è¾¹é™…è´¡çŒ®")
        print(f"âœ… ğŸ”¥ H4å¢å¼º: å¤šæ¨¡å‹Ã—Predictionçª—å£Ã—è·¨å¸‚åœºçŠ¶æ€ä¸‰ç»´éªŒè¯")

        print(f"\nğŸ“Š æ–°å¢H4åˆ†æç»´åº¦:")
        print(f"âœ… SVR vs RF vs LSTM è·¨çª—å£æ€§èƒ½å¯¹æ¯”")
        print(f"âœ… æ¨¡å‹-çª—å£æ€§èƒ½çƒ­å›¾å¯è§†åŒ–")
        print(f"âœ… å¤šæ¨¡å‹ç¨³å®šæ€§ç®±çº¿å›¾åˆ†æ")
        print(f"âœ… æœ€ä¼˜æ¨¡å‹-çª—å£ç»„åˆè¯†åˆ«")
        print(f"âœ… æ¨¡å‹æ€§èƒ½è¶‹åŠ¿çº¿åˆ†æ")
        print(f"âœ… è¯¦ç»†ç»Ÿè®¡è¡¨æ ¼è¾“å‡º")

        print(f"\nğŸ“ å›¾è¡¨æ–‡ä»¶:")
        for i, fig_path in enumerate(research.figures_saved, 1):
            if i == 6:
                print(f"â”œâ”€ {i:02d}. {os.path.basename(fig_path)} ğŸ”¥ (H4ä¸“é—¨åˆ†æ)")
            else:
                print(f"â”œâ”€ {i:02d}. {os.path.basename(fig_path)}")

        print(f"\nğŸ¯ å­¦æœ¯ä»·å€¼:")
        print(f"âœ… ä¸¥æ ¼çš„å››å‡è®¾å®éªŒè®¾è®¡")
        print(f"âœ… H4å¤šæ¨¡å‹ä¸‰ç»´åˆ†æåˆ›æ–°")
        print(f"âœ… å¸‚åœºçŠ¶æ€å¼‚è´¨æ€§æ·±åº¦åˆ†æ")
        print(f"âœ… å¤§è§„æ¨¡æ•°æ®ç»Ÿè®¡éªŒè¯")
        print(f"âœ… å®Œæ•´çš„å¯é‡ç°ç ”ç©¶æ¡†æ¶")
        print(f"âœ… å·¥ä¸šçº§å¤šæ¨¡å‹é€‰æ‹©ç³»ç»Ÿ")
        print(f"âœ… å…¨é¢çš„å¯è§†åŒ–å±•ç¤º")

        # è¾“å‡ºH4å…³é”®å‘ç°
        if research.h4_results and total_experiments > 0:
            all_r2_values = []
            for results_list in [research.h1_results, research.h2_results, research.h3_results, research.h4_results]:
                all_r2_values.extend([r['R2'] for r in results_list])

            if all_r2_values:
                h4_df = pd.DataFrame(research.h4_results)
                h4_overall = h4_df[h4_df['Regime'] == 'Overall']

                print(f"\nğŸ”¥ H4å¢å¼ºå…³é”®å‘ç°:")
                if not h4_overall.empty and 'Model' in h4_overall.columns:
                    # æœ€ä½³ç»„åˆ
                    best_combo = h4_overall.loc[h4_overall['R2'].idxmax()]
                    print(
                        f"â”œâ”€ ğŸ† æœ€ä½³ç»„åˆ: {best_combo.get('Model', 'Unknown')}_H{best_combo['Horizon_H']}å¤© (RÂ²={best_combo['R2']:.4f})")

                    # æ¨¡å‹å¹³å‡æ€§èƒ½
                    model_avg = h4_overall.groupby('Model')['R2'].mean()
                    print(f"â”œâ”€ ğŸ“Š æ¨¡å‹å¹³å‡æ€§èƒ½:")
                    for model, avg_r2 in model_avg.items():
                        print(f"â”‚  â”œâ”€ {model}: {avg_r2:.4f}")

                    # æœ€ä½³çª—å£
                    horizon_avg = h4_overall.groupby('Horizon_H')['R2'].mean()
                    best_horizon = horizon_avg.idxmax()
                    print(f"â”œâ”€ â° æœ€ä½³Predictionçª—å£: H={best_horizon}å¤© (RÂ²={horizon_avg[best_horizon]:.4f})")

                    print(f"â””â”€ ğŸ“ˆ H4å®éªŒæ€»æ•°: {len(research.h4_results)} (åŒ…å«æ‰€æœ‰æ¨¡å‹Ã—çª—å£Ã—å¸‚åœºçŠ¶æ€ç»„åˆ)")

                # æ€»ä½“å‘ç°
                mean_r2 = np.mean(all_r2_values)
                success_rate = len([r for r in all_r2_values if r > 0]) / len(all_r2_values) * 100

                print(f"\nğŸ“ˆ æ•´ä½“å…³é”®å‘ç°:")
                print(f"â”œâ”€ æ•´ä½“å¹³å‡RÂ²: {mean_r2:.4f}")
                print(f"â”œâ”€ æˆåŠŸç‡: {success_rate:.1f}%")

                if research.h1_results:
                    h1_df = pd.DataFrame(research.h1_results)
                    h1_overall = h1_df[h1_df['Regime'] == 'Overall']
                    if not h1_overall.empty:
                        best_model = h1_overall.groupby('Model')['R2'].mean().idxmax()
                        print(f"â”œâ”€ H1æœ€ä½³æ¨¡å‹: {best_model}")

                if research.h2_results:
                    h2_df = pd.DataFrame(research.h2_results)
                    best_features = h2_df.groupby('FeatureSet')['R2'].mean().idxmax()
                    print(f"â”œâ”€ H2æœ€ä½³ç‰¹å¾: {best_features}")

                print(f"â””â”€ ğŸ”¥ H4å¤šæ¨¡å‹éªŒè¯: æˆåŠŸå®ç°SVRÃ—RFÃ—LSTMå…¨è¦†ç›–åˆ†æ")

    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

        # å³ä½¿å‡ºé”™ä¹Ÿå°è¯•ä¿å­˜å·²æœ‰ç»“æœ
        try:
            research.save_results()
            print("âœ… å·²ä¿å­˜éƒ¨åˆ†ç»“æœ")
        except:
            print("âŒ ç»“æœä¿å­˜ä¹Ÿå¤±è´¥")


if __name__ == "__main__":
    main()